\documentclass{article}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{tabularx}
\usepackage{changepage}
\doublespacing
\usepackage[dvipsnames]{xcolor}
\newcommand{\ihat}{\mathbf {\hat \imath}}
\newcommand{\jhat}{\mathbf {\hat \jmath}}
\newcommand{\nhat}{\mathbf {\hat n}}
\DeclareMathOperator{\dis}{d}
\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\beginsp}[1]{\begin{adjustwidth}{2.5cm}{2.5cm}#1\end{adjustwidth}}
\newcommand{\definition}[2]{\textbf{Definition. #1.}\begin{adjustwidth}{1cm}{1cm}#2\end{adjustwidth}}
\newcommand{\theorem}[2]{\textbf{Theorem. #1.}\begin{adjustwidth}{1cm}{1cm}#2\end{adjustwidth}}
\newcommand{\lemma}[2]{\textbf{Lemma. #1.}\begin{adjustwidth}{1cm}{1cm}#2\end{adjustwidth}}
\newcommand{\corrollory}[2]{\textbf{Corollory. #1.}\begin{adjustwidth}{1cm}{1cm}#2\end{adjustwidth}}
\rmfamily
\setlength{\parindent}{0pt}
\usepackage{geometry}
\geometry{
	paper=a4paper,
	top=2.54cm,
	bottom=2.54cm,
	left=2.54cm, 
	right=2.54cm, 
	headheight=14pt, 
	footskip=1.2cm,
	headsep=1.2cm, 
}

\begin{document}
\begin{titlepage}
    \centering
    \vspace*{\fill}

    \vspace*{0.5cm}

    \huge\bfseries
    Glossary: Higher Linear Algebra: Definitions and THeorems

    \vspace*{2cm}

    \large Dylan Wang (z5422214)

    \vspace*{2cm}

    \large May 2023, Term 2

    \vspace*{\fill}
\end{titlepage}
\newpage
\definition{Groups}{A group $G$ is a non-empty set with a binary operation defined on it. That is \begin{enumerate} \item Closure: for all $a$, $b \in G$ a composition $a * b$ is defined and in $G$.\item Associativity: for all $a,b \in G$, $(a*b)*c=a*(b*c)$. \item Identity: There is an element $e \in G$ such that $a * e e * a = a$. \item Inverse: for each $a \in G$ there exists an $a' \in G$ such that $a * a' = a' * a = e*.$ \end{enumerate}If $G$ is a finite set then the order of $G$ is $|G|$, the number of elements in $G$. Technically, a group is the pair $(G, *)$; said as ``the group $G$ under the operation $*$''.\\[1\baselineskip]\textsuperscript{*}It captures the idea of a collection of objects, and came from symmetry; think about actions on a structure, and composing these actions.}~\\
\definition{Abelian Group}{A group $G$ is abelian if the operation satisfies the commutative law \[a * b = b * a \qquad \text{for all} \qquad a,b \in G.\]}
\textbf{Notes on Groups}\begin{itemize}
  \item A composition is a function $*: G \times G \rightarrow G$.
  \item The operation $*$ is not restricted to but it s commonly addition (for abelian groups), mulitiplication (often written as juxtaposition) or composition of functions.
  \item We use power notation for repeated compositions: $a * a * a * \ldots * a = a^n$ and $a^{-n} = (a^{-1})^n$.
\end{itemize}
\textbf{Examples}\begin{itemize}
  \item $(\mathbb{Z}, +)$ is an abelian group;
  \item $(\mathbb{Z}, -)$ is not a group because the inverse of $2$ (or any $n \in \mathbb{Z}, n \neq \pm 1$) is not an integer.
  \item For any integer $m$, the set $\mathbb{Z}_m = \{0, 1, 2, \ldots, m-1\}$ of remainders modul $m$ is a group under addition modulo $m$.
  \item If $p$ is prime, $\mathbb{Z}^*_p = \mathbb{Z}_p \ \{0\}$ is a group under multiplication modulo $p$. This only works for primes because non-primes will lead to a zero result (e.g. $p = 6$, $2 * 3 = 6 \mod 6 = 0$.)
  \item For any set $S$, the set $F$ of bijective functions $f : S \rightarrow S$ is a group under composition, but is not in general abelian.
\end{itemize}
\lemma{Properties of a Group}{Let $(G, *)$ be a group.\begin{itemize}\item There is only one identity element in $G$.\item Each element of $G$ has only one inverse. \item For each $a \in G$, $(a^{-1})^{-1} = a$. \item For every $a,b \in G$, $(a * b)^{-1} = b^{-1} * a^{-1}$. \item Let $a,b,c \in G$. Then if $a * b = a * c$, $b = c$.Similarly, if $b * a = c * a$ then $b = c$.\end{itemize}}
\textbf{Example.}
Let $m$ be a positive integer and consider the set \[C_m = \{e, a, a^2, a^3, \ldots, a^{m-1}\},\]where $a$ is some (undefined) symbol.\\Define an operation on $C_m$ by specifying that $a^0 = e$ (soon; $a^m = e$) and \[a^k * a^l = \begin{cases}
  a^{k+l} & \text{if } k + l < m\\
  a^{k+l-n} & \text{otherwise}
\end{cases}.\]This is an abelian group known as a cyclic group of order $m$ and we often write $C_m$ as $<a: a^m = e>$ and say it is generated by $a$. \\[1\baselineskip]
\definition{Permutation Groups}{Let $\Omega_n = \{1, 2, \ldots,n\}$. As an ordered set, $\Omega_n$ has $n!$ arrangements or permutations. If we think of these as functions, then each permutation is a bijection on $\Omega_n$ (mapping indices).\\[1\baselineskip]Then the set $\mathcal{S}_n$ of all permutations of $n$ objects forms a group under composition of order $n!$. The proof follows from the bijective function on a set example.}~\\
\definition{Small Finite Groups}{A Cayley table shows the compositions associated with a group, usually for small, finite groups.\\[1\baselineskip]Each row must be a permutation of the elements of the group, because:
\begin{itemize}
  \item If we had a repitition in a row (or column), so that $x*a = x*b$, then the cancellation rule will give $a = b$.
  \item If $a^2 = a$ then composing with $a^{-1}$ gives $a = e$, so the identity is the only element that can be fixed.
\end{itemize}}
\textbf{Example.}
\begin{center}
  \includegraphics[scale=0.25]{assets/group_example.png}
\end{center}
\definition{Fields}{A field $(\mathbb{F}, +, \times)$ is a set $\mathbb{F}$ with two binary operations on it, addition $(+)$ and multiplication $(\times)$, where\begin{enumerate}\item $(\mathbb{F}, +)$ is an abelian gruop;\item $\mathbb{F}^* = \mathbb{F} \ \{0\}$ is an abelian group under multiplication, with $0$ being the additive identity;\item The distributive laws $a \times (b + c) = a \times b + a \times c$ and $(a + b) \times c = a \times c + b \times c$ hold.\end{enumerate}Note this satisfies the $12=5 + 5 + 2$ number laws.\\[1\baselineskip]\textsuperscript{*}It is called a `field' to resemble fields in physics; that is, a premise upon which there is rich structure and interplay.}~\\
\lemma{Interplay Between $+$ and $\times$}{Let $\mathbb{F}$ be a field and $a,b,c \in \mathbb{F}$. Then\begin{itemize}\item $a0 = 0$ (additive identity); \item $a(-b) = -(ab)$ (associativity); \item a(b-c) = ab - ac (distributive law); \item if $ab = 0$ then either $a = 0$ or $b = 0$ (proof: suppose $ab = 0$ and $a \neq 0$, then multiply both sides by $a^{-1}$ to give $0 = a^{-1}0 = a^{-1}(ab) = (a^{-1}a)b = 1b = b)$.\end{itemize}}~\\
\definition{Subgroups}{Let $(G,*)$ be a group and $H$ a non-empty subset of $G$.\\Then $H$ is a subgroup of $G$ if $H$ is a group under the restriction of $*$ to $H$.\\We write this as $H \leq G$ and say $H$ inherits the group structure from $G$.\\[1\baselineskip]\textsuperscript{*}The idea is that $H$ is just a smaller bunch of objects within $G$, the whole collection, and also has its structure and properties.}~\\
\lemma{The Subgroup Lemma}{Let $(G, *)$ be a group and $H$ and non-empty subset of $G$.\\Then $H$ is a subgroup of $G$ if and only if \begin{itemize}
  \item for all $a,b \in H$, $a * b \in H$;
  \item for all $a \in H$, $a^{-1} \in H$;
\end{itemize}These are all proved from closure and inverse of the group; associativity is inherited from $G$ and an identity exists via the inverse.\\[1\baselineskip]Note that any subgroup of an abelian group is also an abelian group.}~\\
\textbf{Examples}\begin{enumerate}
  \item Every non-trivial group $G$ has at least two subgroups: $\{e\}$ and $G$.
  \item For any integer $m$ let $m\mathbb{Z}$ be the set of all multiples of $m$. Then $(m\mathbb{Z}, +)$ is a subgroup of $(\mathbb{Z}, +)$. The converse is also true; any subgroup of $(\mathbb{Z}, +)$ is $(m\mathbb{Z}, +)$ for some $m$.
  \item Consider $C_m = <a : a^m = e>$ the cyclic group of order $m$.\\Picking any integer $k$ with $1 < k < m$ we could generate a subgroup $H_k = <a^k>$ of $C_m$ by looking at all powers of $a_k$. Clearly, the order of $H_k$ cannot be larger than $m$; it is strictly less than $m$ if and only if $k$ and $m$ have a common divisor $d > 1$.
  \item Let $n \geq 1$ be any integer. The set of invertible $n \times n$ matrices over a field $\mathbb{F}$ s a group under matrix multiplication. It is non-abelian if $n > 1$. It is called the general linear group GL$(n, \mathbb{F})$.\\They have important subgroups, such as the special linear groups SL$(n,\mathbb{R})$ and SL$(n, \mathbb{C})$ of matrices with determinant $1$, and the group of orthogonal matrices $O(n) \leq$ GL$(n, \mathbb{R})$.
\end{enumerate}\newpage
\definition{Subfields}{If $(\mathbb{F}, +, \times)$ is a field and $\mathbb{E} \subseteq \mathbb{F}$ is also a field under the same operations, then $(\mathbb{E}, +, \times)$ is a subfield of $(\mathbb{F}, +, \times)$, usually written $\mathbb{E} \leq \mathbb{F}$.}~\\
\lemma{The Subfield Lemma}{Let $\mathbb{E} \neq \{0\}$ be a non-empty subset of field $\mathbb{F}$.\\Then $\mathbb{E}$ is a subfield of $\mathbb{F}$ if and only if for all $a,b \in \mathbb{E}$ \[a + b \in \mathbb{E}, \quad -b \in \mathbb{E}, \quad a \times b \in \mathbb{E}, \quad b^{-1} \in \mathbb{E} \; \text{if} \; b \neq 0.\]Proof: The distributive laws are inherited from $\mathbb{F}$, and the rest of the proof comes from applying the subgroup lemma to $(\mathbb{E}, +)$ and $(\mathbb{E}, \times)$.}~\\
\definition{Morphisms}{Let $(G, *)$ and $(H, \circ)$ be two groups. A (group) homomorphism from $G$ to $H$ is a map $\phi : G \rightarrow H$ that respects the two operations, that is where \[\phi(a * b) = \phi(a) \circ \phi(b) \quad \text{for all} \; a,b \in G.\]A bijective homomorphism $\phi: G \rightarrow H$ is called an isomorphism; the groups are then said to be isomorphic, and are considered the same group. isomorphism is an equivalence relation.\\[1\baselineskip]\textsuperscript{*}The word `homomorphism' comes from the Ancient Greek language: homos meaning ``same'' and morphe meaning ``form'' or ``shape''.\\[1\baselineskip]\textsuperscript{**}Homomorphic maps preserve the structure of the domain group while respecting that of the codomain. The idea is if $a * b$, then under the map $\phi$, we hope that (mapped) $a$ behaves the same with (mapped) $b$ in the codomain. If so, they are homomorphic.}~\\
\textbf{Example}. Let $m \geq$ 2 be any integer. Define $\phi: (\mathbb{Z},+) \rightarrow (m\mathbb{Z},+)$ by $\phi(a) = ma$. Show that $\phi$ is an isomorphism of groups.\\
\textbf{Solution.} Firstly \[\phi(a+b)=m(a+b)=ma+mb=\phi(a)+\phi(b).\]The easiest way to show $\phi$ is a bijection is to find the inverse. But if $g \in m\mathbb{Z}$ then $g=ma$ for some $a \in \mathbb{Z}$ and clearly $\phi(a) = g$, so $\phi^{-1}(g) = a$. Thus $\phi$ is an isomorphism.\\[1\baselineskip]
\lemma{Homomorphism Lemma}{Let $(G, *)$ and $(H, \circ)$ be two groups and $\phi$ a homomorphism between them. Then \begin{itemize}\item $\phi$ maps the identity of $G$ to the identity of $H$.\item $\phi$ maps inverses to inverses, i.e. $\phi(a^{-1})=(phi(a))^{-1}$ for all $a \in G$.\item if $\phi$ is an isomorphism frmo $G$ to $H$ then $\phi^{-1}$ is an isomorphism from $H$ to $G$.\end{itemize}}~\\
\definition{Kernel and Image}{Let $\phi : G \rightarrow H$ be a group homomorphism, with $e'$ the identity of $H$.\\The kernel of $\phi$ is the set \[\text{ker}(\phi) = \{g \in G: \phi(g) = e' \}.\]It is the information lost in the map.\\The image of $\phi$ is the set \[\text{im}(\phi) = \{h \in H : h = \phi(g)\}, \; \text{for some} \; g \in G\].It is the approximation given by the map.}~\\
\lemma{Kernel and Image Lemma}{For $\phi : G \rightarrow H$ a group homomorphism, $\text{ker}(\phi) \leq G$ and $\text{im}(\phi) \leq H$.}~\\
\lemma{Isomorphism Lemma}{A homomorphism $\phi$ is one-to-one if and only if $\text{ker}(\phi) = \{e\}$, with $e$ the identity of $G$. If $\phi$ is one-to-one then $text{im}(\phi)$ is isomorphic to $G$.}~\\
\definition{Linear Representation of $G$ on $\mathbb{F}^n$}{If there exists a homomorphism $\phi : G \rightarrow$ GL$(n, \mathbb{F})$ for some $n$ and some field $\mathbb{F}$, then the group im$(\phi)$ is called a linear representation of $G$ on $\mathbb{F}^n$.\\If $\phi$ is one-to-one (so every element maps to a distinct matrix), we call the representation faithful.}~\\
\definition{Permutation Representation}{From above, in the case where $G$ is finite and $H$ is $\mathcal{S}_n$ for some $n$, then we get a permutation representation of the group $G$ as a subgroup of $S_n$.}\newpage
\definition{Vector Space}{Let $\mathbb{F}$ be a field. A vector space over the field $\mathbb{F}$ consists of an abelian group $(V, +)$ and a function from $\mathbb{F} \times V$ to $V$ called scalar multiplication and written $\alpha \vect{v}$ where \begin{enumerate} \item $\alpha(\beta \vect{v}) = (\alpha \beta)\vect{v}$ for all $\alpha, \beta \in \mathbb{F}$ and $\vect{v} \in V$. \item $1\vect{v} = \vect{v}$ for all $\vect{v} \in V$. \item $\alpha (\vect{u} + \vect{v}) = \alpha \vect{u} + \alpha \vect{v}$ for all $\alpha \in \mathbb{F}$ and $\vect{u}, \vect{v} \in V$. \item $(\alpha + \beta) \vect{u} = \alpha \vect{u} + \beta \vect{u}$ for all $\alpha, \beta \in \mathbb{F}$ and $\vect{u} \in V$.\end{enumerate}There are ten axioms here; 5 from the abelian group, closure of scalar multiplication, and four explicit ones. The $+$ in $(V, +)$ may be distinguished as vector addition.\\[1\baselineskip]\textsuperscript{*}Think of a space as a set with some added structure; i.e. an abelian group (vector addition) and a scalar multiplication function. This should be thought of quite loosely/abstractly.}~\\
\lemma{2.1}{Let $V$ be a vector space over field $\mathbb{F}$. For all $\vect{v}, \vect{w} \in V$ and $\lambda \in \mathbb{F}$ then \begin{itemize}
  \item $0\vect{v} = \vect{0}$ and $\lambda \vect{0} = \vect{0}$.
  \item $(-1)\vect{v} = -\vect{v}$.
  \item $\lambda \vect{v} = \vect{0}$ implies either $\lambda = 0$ or $\vect{v} = \vect{0}$.
  \item If $\lambda \vect{v} = \lambda \vect{w}$ and $\lambda \neq 0$ then $\vect{v} = \vect{w}$.
\end{itemize}}~\\
\textbf{Standard Vector Space Examples.}
\begin{enumerate}
  \item $n$-tuples.\begin{center}
    \includegraphics[scale=0.3]{assets/vector_space_eg.png}\newpage
  \end{center}
  \item Geometric Vectors.\begin{center}
    \includegraphics[scale=0.10]{assets/geometric_vecs.png}
  \end{center}
  \item Matrices.\\For any positive integers $p$ and $q$ the set $M_{p,q}(\mathbb{F})$ is the set of $p \times q$ matrices with elements from $\mathbb{F}$.\\Then $M_{p,q}(\mathbb{F})$ is a vector spsace over $\mathbb{F}$ with vector addition with the usual addition of matrices and scalar multiplication multiplying each element of the matrix.
  \item Polynomials.\\The set of all Polynomials with coefficients in $\mathbb{F}, \mathcal{P}(\mathbb{F}),$ is a vector space over $\mathbb{F}$ with \[(f+g)(x) = f(x) + g(x) \quad \text{for all} \quad x \ in \mathbb{F} \\ (\lambda f)(x) = \lambda f(x) \quad \text{for all} \quad \lambda, x \in \mathbb{F}.\]Similarly, $\mathcal{P}(F)$ (polynomials of degree $n$ or less) is a vector space over $\mathbb{F}$. Note this example shows `vector spaces' can appear abstract from actual vectors! We just need vector $+$ and $\times$.
  \item Function Spaces.\\Let $X$ be a non-empty set and $\mathbb{F}$ be a field. Then define \[\mathcal{F}[X] = \{f: X \rightarrow \mathbb{F} \}.\]The set $\mathcal{F}[X]$ is a vector space over $\mathbb{F}$ if we define \begin{itemize}\item the zero in $\mathcal{F}[X]$ to be the zero function: $x \rightarrow 0$ for all $x \in X$.
  \item $(f+g)(x) = f(x) + g(x)$ for all $x \ in X$.
  \item $(\lambda f)(x) = \lambda (f(x))$ for all $x \in X$.
  \end{itemize}
\end{enumerate}\newpage
\definition{Subspace}{If $V$ is a vector space over $\mathbb{F}$ and $U \subseteq V$, then $U$ is a subspace of $V$, written $U \leq V$, if it is a vector space over $\mathbb{F}$ with the same addition and scalar multiplication as in $V$.\\[1\baselineskip]Every vector space has $\{\vect{0}\}$, the trivial subspace, and itself as subspaces.}~\\
\lemma{Subspace Test Lemma}{Suppose $V$ is a vector space over the field $\mathbb{F}$ and $U$ is a non-empty subset of $V$. Then $U$ is a subspace of $V$ if and only if for all $\vect{u}, \vect{v}, \in U$ and $\alpha \in \mathbb{F}$, $\alpha \vect{u} + \vect{v} \in U$.\\[1\baselineskip]\textbf{Proof}: All of the axioms are inherited from $V$ except for closure and that the zero vector is in $U$. But setting $\alpha = 1$ proves $U$ is closed under addition. With $\alpha = -1$ and $\vect{v} = \vect{u}$ we get $\vect{0} \in U$. Hence we can set $\vect{v} = \vect{0}$ to get closure under scalar multiplication.}~\\
\textbf{Example.} In $\mathbb{R}^2$ consider the subset \[U = \{ \vect{x} = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} : x_1 + x_2 = 0 \}.\] Prove that $U$ is a subspace.\\
\textbf{Proof}: Clearly, $\vect{0} \in U$ so $U$ is not empty.\\Suppose $\vect{x} = \begin{pmatrix}x_1 \\ x_2\end{pmatrix}$ and $\vect{y} = \begin{pmatrix}y_1 \\ y_2\end{pmatrix}$ are in $U$, so $x_1 + x_2 = 0$ and $y_1 + y_2 = 0$.\\Then $\alpha\vect{x} + \vect{y} = \begin{pmatrix}\alpha x_1 + y_1 \\ \alpha x_2 + y_2\end{pmatrix}$ for $\alpha \in \mathbb{R}$ and $(\alpha x_1 + y_1) + (\alpha x_2 + y_2) = \alpha(x_1 + x_2) + (y_1 + y_2) = 0$.\\So $\alpha \vect{x} + \vect{y} \in U$ and $U \leq \mathbb{R}^2$.\\[1\baselineskip]
\definition{Linear Combination}{Let $V$ be a vector space over $\mathbb{F}$. A finite linear combination of vectors $\vect{v}_1, \vect{v}_2, \ldots, \vect{v}_n$ in $V$ is any vector which can be expressed\[\alpha_1 \vect{v}_1 + \alpha_2 \vect{v}_2 + \ldots + \alpha _n \vect{v}_n ,\]where the $\alpha_k$ are scalars.\\[1\baselineskip]\textsuperscript{*}Think of a linear combination as a combination of linear, i.e. $\vect{v}^1$, vectors.}~\\
\definition{Span}{If $S$ is a subset of $V$, then the span of $S$ is \[\text{span}(S) = \{\text{all finite linear combinations of vectors in }S\}.\]We say that $S$ spans $V$, or is a spanning set for $V$, if span$(S) = V$.\\[1\baselineskip]\textsuperscript{*}i.e. given a subset of vectors, forming its span is essentially doing everything to the members of the set that can be done within the rules of a vector space.\\Clearly, $S \subseteq$ span$(S)$ and span$(S)$ is a subset of $V$.}~\\
\lemma{Lemma 2.3}{If $S$ is a non-empty subset of a vector space $V$, then span$(S)$ is a subspace of $V$.\\[1\baselineskip]\textbf{Proof}: Since $S \subseteq$ span$(S)$, span$(S)$ is non-empty.\\But if $\vect{v}$, $\vect{w} \in S$, then $\lambda \vect{v} + \vect{w}$ is a linear combination of two linear combinations of elements of $S$, and so is a linear combination of elements of $S$.\\Thus $\lambda \vect{v} + \vect{w} \in$ span$(S)$ and so span$(S) \leq V$.}~\\
\definition{Linear Independence}{A subset $S$ of a vector space $V$ is linearly independent if for all vectors $\vect{v}_1, \vect{v}_2, \ldots, \vect{v}_n$ in $S$ (with $n \geq 1$) the equation \[\alpha_1 \vect{v}_1 + \alpha_2 \vect{v_2} + \ldots + \alpha _n \vect{v}_n = \vect{0},\]with $\alpha _i \in \mathbb{F}$ implies $\alpha_i = 0$ for all $i = 1\ldots n$.\\[1\baselineskip]\textsuperscript{*}i.e. none of the vectors are linear combinations of each other so that none can cancel each other out, and for their sum to be zero, they must be each be multiplied by 0.}
\lemma{Definition of Linear Dependence}{If $S = \{ \vect{v}_1, \ldots , \vect{v}_n \}$ is a linearly dependent set in $V$ then there is an $i$, $2 \leq i \leq k$ such that \[ \vect{v}_i = \sum_{j=1}^{i-1} \beta _j \vect{v}_j,\]i.e. at least one vector is a linear combination of its predecessors.\\\textbf{Proof}: Since $S$ is linearly dependent, there is a non trivial solution to $\alpha_1 \vect{v}_1 + \alpha_2 \vect{v_2} + \ldots + \alpha _n \vect{v}_n = \vect{0}$. For such a solution, let $i$ be the index o the last non-zero $\alpha_i$. Then $-\alpha_i \vect{v}_i = \sum_{j=1}^{i-1} \alpha_j \vect{v}_j$ and divide by $- \alpha_i$ for the result.}~\\
\theorem{Theorem 2.5}{In any vector space
\begin{itemize}
  \item Any subset of a linearly independent set is linearly independent.
  \item \begin{enumerate}
    \item If $\vect{v} \in$ span$(S)$, then $S \cup \{ \vect{v} \}$ is linearly dependent.
    \item If $S$ is linearly independent and $S \cup \{ \vect{v} \}$ is linearly dependent, then $\vect{v} \in $ span$(S)$.
  \end{enumerate}
  \item \begin{enumerate}
    \item If $S_1 \subseteq S_2$, then span$(S_1) \subseteq$ span$(S_2)$.
    \item If $S_1 \subseteq$ span$(S_2)$, then span$(S_1) \subseteq$ span$(S_2)$. \{Any linear combination of vectors in $S_1$ is a linear combination of vectors already in span$(S_2)$.\}
  \end{enumerate}
  \item span$(S) \cup \{ \vect{v} \} = $ span$(S)$ if and only if $\vect{v} \in $ span$(S)$.
  \item If $S$ is linearly dependent, then there is a vector $\vect{v}$ in $S$ such that span$(S) \backslash \{ \vect{v} \} = $ span$(S)$.
  \item In $\mathbb{F}^p$, if $P \in$ GL$(p, \mathbb{F})$ is an invertible matrix and $\{ \vect{v}_i \}$ is linearly independent, then the set $\{ P \vect{v}_i \}$ is also linearly independent. \{Proof by contradition\}.
\end{itemize}}~\\
\definition{Bases}{Let $S \subseteq V$. The set $S$ is a basis for $V$ over $|mathbb{F}$ if and only if $V =$ span$(S)$, and $S$ is a linearly dependent set.\\[1\baselineskip]\textsuperscript{*}Think the `basic' foundation of a vector space; the minimal set of vectors from which we can form all vectors in $V$ via linear combinations.}
\begin{center}
  \includegraphics[scale=0.23]{assets/basis_eg.png}
\end{center}
[See Chapter 2 Video 8 of lectures for examples on matrices, polynomials, function spaces, etc.]\\[1\baselineskip]
\theorem{2.7}{Let $V$ be a vector space over $\mathbb{F}$ and $S$ a finite spanning set. Then $S$ contains a finite basis for $V$.}~\\
\lemma{The Exchange Lemma}{Suppose that $S$ is a finite spanning set for $V$ and that $T$ is a (finite) linearly independent subset of $B$ with $|T| \leq |S|$.\\Then there is a spanning set $S'$ of $V$ such that \[T \subseteq S' \quad \text{and} \quad |S'| = |S|.\]\textsuperscript{*}The intuition is we swap out one element from the finite spanning set $S$ in favour of a suitable element from a smaller linearly independent set $T$; hence the name.\\[1\baselineskip]
\textbf{Corrolary. 2.9.}\\If $S$ is a finite spanning set for a vector space $V$ and $T$ is a linearly independent subset of $V$, then $T$ is finite and $|T| \leq |S|$.}~\\
\theorem{2.10}{Let $V$ be a vector space over $\mathbb{F}$ with a finite spanning set and $T$ a linearly independent subset of $V$.\\Then there is a basis $B$ of $V$ which contains $T$.\\ \textsuperscript{*}i.e. any linearly independent set can be extended to a basis (if there is a finite spanning set).}~\\ 
\theorem{2.6}{If a vector space $V$ admits a finite spanning set, it admits a finite basis and all bases contain the same number of elements.}~\\
\definition{Dimension}{The dimension of a vector space $V$ is the size of a basis if $V$ has a finite basis or infinity otherwise, denoted as dim$(V) = n$ or dim$(V) = \infty$.}~\\
\lemma{2.11}{Let $V$ be a finite dimensional vector space and suppose dim$(V) = n$. \begin{enumerate} \item The number of elements in any spanning set is at least $n$. \item The number of elements in any independent set is no more than $n$. \item If span$(S) = V$ and $|S| = n$ then $S$ is a basis. \item If $S$ is a linearly independent set and $|S| = n$ then $S$ is a basis. \end{enumerate} }~\\
\theorem{2.12}{Let $V$ be a finite dimensional vector space over $\mathbb{F}$.\\Then $\mathcal{B} = \{ \vect{v_1}, \ldots , \vect{v}_n \}$ is a basis for $V$ if and only if every $\vect{x} \in V$ can be written uniquely as $\vect{x} = \sum_{i=1}^n \alpha _i \vect{v}_i, \; \alpha _i \in \mathbb{F}$.}~\\
\definition{Coordinates}{Suppose $V$ is a vector space of dimension $n$ over $\mathbb{F}$ and suppose $\mathcal{B} = \{ \vect{v}_1, \ldots , \vect{v}_n \}$ is an ordered basis for $V$ over $\mathbb{F}$.\\If $\vect{v} \in V$ then $\vect{v} = \sum_{i=1}^n \alpha_i \vect{v}_i$ with the $\alpha_i$ unique by theorem 2.12.\\We call $\alpha = \begin{pmatrix}\alpha_1 \\ \vdots \\ \alpha_n\end{pmatrix}$ the coordinate vector of $\vect{v}$ with respect to $\mathcal{B}$, and refer to the $\alpha_i$ as the coordinates of $\vect{v}$. A useful notation is \[\vect{\alpha} = [\vect{v}]_{\mathcal{B}} \; \text{if} \; \vect{v} = \sum_{i=1}^n \alpha_i \vect{v} _i.\]\textsuperscript{*}A coordinate vector is a representation of a vector as an ordered list of numbers that describes the vector in terms of (i.e. as a linear combination of) a particular ordered basis.}~\\
\definition{2.8. Sum of Two Subspaces}{The sum $S + T$ of two subspaces is defined as \[S + T = \{ \vect{a} + \vect{b} : \vect{a} \in S, \; \vect{b} \in T \}.\]If $S \cap T = \{ \vect{0} \}$ then we call the sum as a direct sum and denote it as $S \oplus T$. The result in either case is a subspace.}\newpage
\lemma{2.13}{The sum of subspaces $S$ and $T$ is direct if and only if any vector $\vect{x} \in S + T$ can be written in a unique way as $\vect{x} = \vect{a} + \vect{b}, \vect{a} \in S, \vect{b} \in T$.}~\\
\theorem{2.14}{Suppose $S$ and $T$ are finite dimensional subspaces of vector space $V$. Then \[\text{dim}(S) + \text{dim}(T) = \text{dim}(S+T) + \text{dim}(S \cup T).\]}
\corrollory{2.15}{For a direct sum of finite dimensional spaces \[\text{dim}(S) + \text{dim}(T) = \text{dim}(S \oplus T).\]}
\lemma{2.16}{Let $V$ be a finite dimensional vector space and $X \leq V$.\\Then there is a subspace $Y$ for which $V = X \oplus Y$.}~\\
\definition{2.9. The External Direct Sum}{Let $X$ and $Y$ be two vector spaces over the same field $\mathbb{F}$\\The Cartesian product $X \times Y$ can be made into a vector space over $|mathbb{F}$ with the obvious definitions \[(\vect{x}_1,\vect{y}_1)+(\vect{x}_2,\vect{y}_2)=(\vect{x}_1+\vect{x}_2,\vect{y}_1+\vect{y}_2) \quad \text{and} \quad \lambda(\vect{x}_1,\vect{y}_1)=(\lambda \vect{x}_1,\lambda \vect{y}_1).\]With this structure we call the Cartesian product the (external) direct sum of $X$ and $Y$, $X \oplus Y$.}
\end{document}